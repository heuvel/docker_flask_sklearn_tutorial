# Deploying an API with Docker
## Introduction
The Iris flower data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper.  The iris set became a typical test case for many statistical classification techniques in machine learning.

The goal of this session is to run and modify a (REST) API that is able to classify an observation from the Iris dataset. This means that we give the API measurements of an observation and that the API will return one of the three classes from the Iris dataset.

This Github repo (https://github.com/heuvel/docker_flask_sklearn_tutorial) contains the following components:

- A Jupyter Notebook with Python code that fits a model on the iris dataset and saves the model into a Python Pickle file.
- A small API that is able to classify an observation given on the endpoint `/classify` with the four variables as GET-params: `/classify/sl/sw/pl/pw`
  - sl, sw, pl, pw are the four measurements that make up one observation: sepal length, sepal width, petal length and petal width
  - Example of a call to the API with a measurement is `localhost:5000/classify/2.3/3.3/2.0/2.5/`
- A Dockerfile that generates a Docker Image that is able to run this API

In this session we start with running the final version of the API. If the API works, we will modify parts of the application and rebuild the docker image.

## Running the API
The first thing we're going to do is to run the docker image with the API. Start with pulling the image to your local repository. You can use the command `docker pull heuvel/iris_api` to download the docker image.

- Question: Pull/download the docker image
- Answer: `docker pull heuvel/iris_api`

By running `docker images` in the terminal, you see that this image is available in your local docker repository. This image is ready to run. With the command `docker run`, you can start the image. Give the docker container a name with the flag `--name=api`. Also make sure the container runs as a "daemon" (with detached terminal) by supplying the flag `--detach`

- Question: Start the docker image with name `api`
- Answer: `docker run --detach --name=api heuvel/iris_api`

Now the API is running and listening at localhost, port 5000: `http://localhost:5000`. Docker provides also a method to list all the running docker containers. With `docker ps` you can display an overview of all running docker images.

- Question: list all running docker containers in a new terminal window.
- Answer: `docker ps`

In the overview generated by `docker ps`, you also see that the API is running. Let's connect with the API.

- Question: open your browser and try to connect with the API: `http://localhost:5000` (or, if you are running this at a remote server, use that servers' IP addres, for instance: http://52.210.76.86:5000)
- Answer: not possible

You'll see that it is not possible to reach the API outside of this docker container. But we have just seen that it is running using the `ps` command. Open a bash prompt to the running docker container with `docker exec -it api /bin/bash`

- Question: Try to reach the API with wget (use flags `-qO-` to just print the output to the terminal (yes, that is an Oh, not zero...))
- Answer: `wget -qO- http://localhost:5000`

The result is a small HTML file that is not well displayed on the terminal. The API only accepts requests from inside the container.
You'll see that it is not possible to reach the API outside of this docker container. Therefore, we must open a port that allows us to communicate with the API. With the `--publish=[host port]:[container port]` option in the `docker run` command we are able to bind a port of the docker container to a port on the host machine.

- Question: Try to start this image again with port 5000 published on port 5000.
- Answer: not possible, docker container still exists

You will observe that Docker returns with an error: `docker: Error response from daemon: Conflict. The name "/api" is already in use by container`.

You can stop a container with the command `docker stop [container name]`

- Question: Try to stop the running container called 'api'
- Answer: `docker stop api`

We only stopped the API container, but we did not remove it. With the `docker ps -a` you can list all the docker containers, also the 'stopped' containers. We first have to remove the container with the name `api` before we are allowed to run a new one. You can remove the container with the command `docker rm [container name]`

- Question: Remove the container with `docker rm api`
- Answer: `docker rm api`

If you run `docker ps -a`, you'll see that no containers are running or stopped. Try to run the API again with the port 5000 published

- Question: Stop the running API and try to run this API again with port 5000 published on port 5000.
- Answer: `docker run --detach --name=api --publish=5000:5000 heuvel/iris_api`

Once you see that the API is running, you can try to connect to the API in a web browser. If all is working well, you are able to connect to the API.

- Question: open your browser and try to connect with the API: `http://localhost:5000` (or, if you are running this at a remote server, use that servers' IP addres, for instance: http://52.210.76.86:5000)
- Answer: Your browser displays "This is the Iris API"

This API publishes the endpoint `/classify` that you can call with the four measurements, as explained in the introduction.

- Question: Call the API with a measurement on the `/classify` endpoint.
- Answer: `http://localhost:5000/classify/6.3/3.3/6.0/2.5/`

Well done, the API is running.

### Summary
What you have learnt:

* pull an image from the Docker hub
* run and stop the image in detached mode
* execute a specific binary within the container
* list running and stopped containers
* remove stopped containers
* publish container ports to the outside world

## Modifying the API
> To skip over this how-to-adapt-the-api section, just copy `app_final.py` over the file `app.py` in the directory `docker_flask_sklearn_tutorial/iris_api/api`. You can do this either through the Jupyter file browser or via the terminal. If you want to do this through the terminal, exectute commands `mv app.py app.py.old` and `mv app_final.py app.py`. Subsequently, stop and execute the docker container again.

The API now only returns a number ([0-2]). This number responds to one of the class labels. In this chapter, we are going to modify the API so it will return the label setosa, versicolor or virginica. Clone the GitHub repository with `git clone https://github.com/heuvel/docker_flask_sklearn_tutorial.git` and open the file `app.py`.
You will see that we only need a few lines of code to create an API that is able deploy our classifier as a service. The function `classify` is the function that is able to classify one observation.

In the python environment, a dict (`model`) is available with three entries: 'classifier', 'target_names' and 'feature_names'. The object `model['classifier']` is a trained sklearn model. We can run the `predict`-function on the object to classify the measurement.
The function returns an index. The index can be used to retrieve the label of the class with use of the `target_names` array inside `model`. For example: the code `print model['target_names'][1]` returns the class label with index 1.

The feature names are also available in the model. If you want, you can also modify the API so it also returns the given measurements together with the feature names.

- Question: Modify app.py so it returns the class label instead of the class index.
- Answer: see app_final.py.

The docker host that we use is a bare system that does not have any of the required dependencies to run the model. These are included in the Docker image. To test the changes to our `api.py` file, we will need to run the image with this altered file...

## Test the new version of the API
In this chapter, we will test the new version of `app.py` in the Docker container. In this phase, we do not want to build a complete new image only for testing the new version of the app. It is very likely that `app.py` contains an error or that some functionality is not working as desired. With docker, we can mount a volume to the container and 'override' the old version of `app.py`. With the `--volume` option, we mount a local directory to a directory inside the docker container.

- Question: extend your `docker run` command with a volume mount. The directory of the python file inside the docker container is `/opt/api`. This directory initially contains the `model.pkl` and `app.py` file.
- Answer: First stop the old container and remove it. Then: `docker run --detach --name=api --publish=5000:5000 --volume=~/docker_flask_sklearn_tutorial/iris_api/api/:/opt/api heuvel/iris_api`.

You can fiddle around modifying the API. Remember to re-run (`stop`, `rm`, `run`) the container inbetween changes you make to `app.py`.

Once you are finished with all the adjustments to `app.py`, you can go to the next section. In this section, we will embed the new app.py inside the image.

## Embed the new app.py into the image
The aim of our Docker image is to deliver container functionality that has no external dependencies. During development it is often convenient to mount a local directory into our container. But to deliver a simple "module" that "just works", we need to include our `api.py` and model into the Docker image.

When you are finished developing a new version of our model and backend, it is best practice to embed these files into the image itself instead of mounting a directory. With embedding the model and the API, all dependencies are included in the image.

Building a Docker image is done using a Dockerfile. The cloned git repo contains a Dockerfile that builds this image. The base image used is `buildo/docker-python2.7-scikit-learn` which is another image at Docker Hub, created by user buildo. That is a raw base image that has python 2.7 and scikit-learn, numpy and scipy installed. It forms a good basis for our experiments.

- Question: open this Dockerfile and try to understand the different steps in this file. More information can be found on https://docs.docker.com/engine/reference/builder/

The command `COPY api/* /opt/api/` copies all the necessary files (model, python api) into the docker image. With `CMD ["python", "app.py"]`, we tell the image to run `python app.py` when we run the container through `docker run`.

Now we are going to rebuild the image. To build a image, we use the command `docker build .` (note the dot) in the directory where the `Dockerfile` is located. With the flag `-t`, we tag the image with a name. It is possible to overwrite the old image.

- Question: rebuild the image with the name `[your name]_iris_api`, for example `joris_iris_api`
- Answer: `docker build -t joris_iris_api .`. Note that all containers running this image should be started using that tag you have just created. In the example: `docker run ... joris_iris_api`

If the process is successful, you can run `docker images` to see that a new version of the image is available in your local repository.

- Question: run the new version of the API without the volume mount
- Answer: `docker run --detach --name=api --publish=5000:5000 joris_iris_api`

## Extend the API
You are free to extend the API with other information. Some suggestions:

- Train a model on another dataset
- Create an additional endpoint that returns more information about the trained model
- Return an image of the iris class together with the class label.
